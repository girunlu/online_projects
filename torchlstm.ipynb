{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb889a67-00d8-4d95-8be6-8abc0fd51184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b63b85-0b4c-4b4f-9d6b-35e242717f1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset, model, training\n",
    "class data(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        \n",
    "        self.x = torch.from_numpy(x).to(device)\n",
    "        self.y = torch.from_numpy(y).to(device)\n",
    "        self.n_samples = self.x.size(0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a32ac-746a-418b-bf68-fc9f6b207276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15246 3812\n",
      "203 54\n"
     ]
    }
   ],
   "source": [
    "xdata, ydata = np.load(\"datax.npy\"), np.load(\"target.npy\")\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(xdata,ydata, test_size=.2)\n",
    "\n",
    "train_data = data(xtrain, ytrain)\n",
    "test_data = data(xtest, ytest)\n",
    "\n",
    "print(len(train_data), len(test_data))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=75, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=70, shuffle=True, drop_last=True)\n",
    "\n",
    "print(len(train_loader), len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70e5132-7ade-4afb-b850-a47fb8ab03c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##lstm stuff check how lstm layer works\n",
    "class extract_tensor(nn.Module):\n",
    "    def forward(self, x):\n",
    "        tensor, _ = x\n",
    "        return tensor[:,-1,:] #the usable lstm output is the last matrix of the hidden state\n",
    "\n",
    "# calculating accuracy in training loop for probabilities  \n",
    "def accuracy(logits, targets):\n",
    "    preds = F.softmax(logits, dim=1)\n",
    "    counts = (torch.argmax(targets,dim=1) == torch.argmax(preds, dim=1)).sum()\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a6e9501-9c0e-4387-8f39-00865c68ba63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTModel(\n",
       "  (lstm): LSTM(51, 96, num_layers=2, batch_first=True, dropout=0.15)\n",
       "  (arch): Sequential(\n",
       "    (0): extract_tensor()\n",
       "    (1): ReLU()\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=96, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building the model\n",
    "class LSTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTModel, self).__init__()\n",
    "        \n",
    "        self.input_size = 51\n",
    "        self.hidden_size = 96\n",
    "        self.seq_len = 45\n",
    "        self.outsize = 4\n",
    "        self.num_layers = 2\n",
    "        self.batch_first = True\n",
    "        self.dropout = .15\n",
    "        \n",
    "        # i could sum them up in the seq part but i just didnt want to\n",
    "        self.lstm = nn.LSTM(input_size=self.input_size, hidden_size=self.hidden_size,\n",
    "                                          num_layers=self.num_layers, batch_first=self.batch_first,\n",
    "                                          dropout=self.dropout)\n",
    "        \n",
    "        self.arch = nn.Sequential(extract_tensor(),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Flatten(),\n",
    "                                 nn.Linear(self.hidden_size, self.outsize))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        #notice this is not in the init section, it is because we want to run the model on different batch sizes (e.g. 64 for training 1 for predicting)\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
    "        \n",
    "        nn.init.xavier_normal_(h0)\n",
    "        nn.init.xavier_normal_(c0)\n",
    "        \n",
    "        out = self.lstm(x, (h0,c0))\n",
    "        \n",
    "        out = self.arch(out)\n",
    "        return out\n",
    "\n",
    "model = LSTModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ed3db51-430f-4a07-a5ca-362d7218bf48",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, step 68/203, loss 1.1716\n",
      "epoch 1, step 136/203, loss 0.8373\n",
      "epoch 1, step 203/203, loss 0.7776\n",
      "accuracy is 0.5219\n",
      "epoch 2, step 68/203, loss 0.6972\n",
      "epoch 2, step 136/203, loss 0.4454\n",
      "epoch 2, step 203/203, loss 0.4514\n",
      "accuracy is 0.7440\n",
      "epoch 3, step 68/203, loss 0.3395\n",
      "epoch 3, step 136/203, loss 0.4052\n",
      "epoch 3, step 203/203, loss 0.4631\n",
      "accuracy is 0.8314\n",
      "epoch 4, step 68/203, loss 0.2846\n",
      "epoch 4, step 136/203, loss 0.3121\n",
      "epoch 4, step 203/203, loss 0.4033\n",
      "accuracy is 0.9089\n",
      "epoch 5, step 68/203, loss 0.1645\n",
      "epoch 5, step 136/203, loss 0.3447\n",
      "epoch 5, step 203/203, loss 0.2434\n",
      "accuracy is 0.9328\n",
      "epoch 6, step 68/203, loss 0.0692\n",
      "epoch 6, step 136/203, loss 0.1407\n",
      "epoch 6, step 203/203, loss 0.0995\n",
      "accuracy is 0.9579\n",
      "epoch 7, step 68/203, loss 0.1743\n",
      "epoch 7, step 136/203, loss 0.0276\n",
      "epoch 7, step 203/203, loss 0.1695\n",
      "accuracy is 0.9601\n",
      "epoch 8, step 68/203, loss 0.0874\n",
      "epoch 8, step 136/203, loss 0.1086\n",
      "epoch 8, step 203/203, loss 0.1454\n",
      "accuracy is 0.9725\n",
      "epoch 9, step 68/203, loss 0.2535\n",
      "epoch 9, step 136/203, loss 0.0326\n",
      "epoch 9, step 203/203, loss 0.1519\n",
      "accuracy is 0.9765\n",
      "epoch 10, step 68/203, loss 0.0271\n",
      "epoch 10, step 136/203, loss 0.0208\n",
      "epoch 10, step 203/203, loss 0.0617\n",
      "accuracy is 0.9710\n",
      "epoch 11, step 68/203, loss 0.0074\n",
      "epoch 11, step 136/203, loss 0.0477\n",
      "epoch 11, step 203/203, loss 0.1960\n",
      "accuracy is 0.9844\n",
      "epoch 12, step 68/203, loss 0.0062\n",
      "epoch 12, step 136/203, loss 0.0890\n",
      "epoch 12, step 203/203, loss 0.0094\n",
      "accuracy is 0.9852\n",
      "epoch 13, step 68/203, loss 0.0128\n",
      "epoch 13, step 136/203, loss 0.3076\n",
      "epoch 13, step 203/203, loss 0.0484\n",
      "accuracy is 0.9754\n",
      "epoch 14, step 68/203, loss 0.0054\n",
      "epoch 14, step 136/203, loss 0.0257\n",
      "epoch 14, step 203/203, loss 0.0032\n",
      "accuracy is 0.9959\n",
      "epoch 15, step 68/203, loss 0.0295\n",
      "epoch 15, step 136/203, loss 0.0051\n",
      "epoch 15, step 203/203, loss 0.0678\n",
      "accuracy is 0.9938\n",
      "epoch 16, step 68/203, loss 0.0036\n",
      "epoch 16, step 136/203, loss 0.0026\n",
      "epoch 16, step 203/203, loss 0.0778\n",
      "accuracy is 0.9940\n",
      "epoch 17, step 68/203, loss 0.0101\n",
      "epoch 17, step 136/203, loss 0.0032\n",
      "epoch 17, step 203/203, loss 0.0016\n",
      "accuracy is 0.9940\n",
      "epoch 18, step 68/203, loss 0.1684\n",
      "epoch 18, step 136/203, loss 0.1463\n",
      "epoch 18, step 203/203, loss 0.0215\n",
      "accuracy is 0.9607\n",
      "epoch 19, step 68/203, loss 0.0164\n",
      "epoch 19, step 136/203, loss 0.0090\n",
      "epoch 19, step 203/203, loss 0.0025\n",
      "accuracy is 0.9910\n",
      "epoch 20, step 68/203, loss 0.0029\n",
      "epoch 20, step 136/203, loss 0.0018\n",
      "epoch 20, step 203/203, loss 0.0022\n",
      "accuracy is 1.0000\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "num_epochs = 20\n",
    "total_step = len(train_loader)\n",
    "lr = 5e-4\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =lr)\n",
    "\n",
    "\n",
    "correct = 0\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    for i, (inputs, outputs) in enumerate(train_loader):\n",
    "        inputs = inputs.float().to(device)\n",
    "        outputs = outputs.float().to(device)\n",
    "        \n",
    "        logits = model(inputs) \n",
    "        \n",
    "        loss = loss_fn(logits, outputs) #loss fn has softmax in it in pytorch, thats why we work with logits and not predictions\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        correct += accuracy(logits, outputs) #number of correct predictions\n",
    "        \n",
    "\n",
    "        \n",
    "        if (i+1)%(68)==0: #optional loss tracing\n",
    "            print(f\"epoch {epoch}, step {i+1}/{total_step}, loss {loss:.4f}\")\n",
    "    print(f\"epoch {epoch}, step {i+1}/{total_step}, loss {loss:.4f}\")\n",
    "\n",
    "    if epoch%6==0: #handmade learning rate scheduler\n",
    "        lr/=2\n",
    "    \n",
    "    acc = correct/(total_step*75) #calculating accuracy on whole dataset\n",
    "    print(f\"accuracy is {acc:.4f}\")\n",
    "    correct = 0 #resetting for next epoch\n",
    "    \n",
    "    #early stop ;)\n",
    "    #if acc >= 0.99:\n",
    "        #print(\"acc is achieved\")\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa4117eb-8b84-43e7-9a5a-10a0af475e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3780, 4), (3780, 4))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validation\n",
    "preds = []\n",
    "trgets = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for inpt, target in test_loader:\n",
    "    inpt = inpt.float().to(device)\n",
    "    target = target.float().to(device)\n",
    "    \n",
    "    with torch.no_grad(): #running model on samples without calcualting grads / we dont use them\n",
    "        logit = model(inpt)\n",
    "        \n",
    "    pred = F.softmax(logit, dim=1) # calculating probabilities\n",
    "    \n",
    "    preds.append(F.one_hot(torch.argmax(pred, dim=1)).cpu().numpy()) #turning probabilities into onehot so that we can calculate confusion matrix\n",
    "    trgets.append(target.cpu().numpy()) #its already in onehot\n",
    "    \n",
    "preds = np.array(preds, dtype=np.int32).reshape(-1,4) #from (steps, batch_size, output) to (samples, output)\n",
    "trgets = np.array(trgets, dtype=np.int32).reshape(-1,4)\n",
    "preds.shape, trgets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a172355-7c8f-4457-93d5-5a2fa19ed3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([0, 1, 2, 3], dtype=int64),\n",
       "  array([1036,  764,  903, 1077], dtype=int64)),\n",
       " (array([0, 1, 2, 3], dtype=int64),\n",
       "  array([1036,  764,  903, 1077], dtype=int64)))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = np.argmax(preds, axis=1)\n",
    "trues = np.argmax(trgets, axis=1) ## collapsing onehot to index vector among samples\n",
    "\n",
    "np.unique(pr, return_counts=1), np.unique(trues, return_counts=1) #collapsing columns to see distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0dfb59a-d97a-4bfe-8f22-128ccb8307f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix over one class / notice array names are hard coded (preds, trgets)\n",
    "def get_matrix(class1):\n",
    "    zer = 0\n",
    "    one = 0\n",
    "    two = 0\n",
    "    tre = 0\n",
    "\n",
    "    for inx in range(len(preds)):\n",
    "        if np.argmax(trgets[inx]) == class1:\n",
    "            if np.argmax(preds[inx]) == 0:\n",
    "                zer+=1\n",
    "            elif np.argmax(preds[inx]) == 1:\n",
    "                one+=1\n",
    "            elif np.argmax(preds[inx]) == 2:\n",
    "                two+=1\n",
    "            elif np.argmax(preds[inx]) == 3:\n",
    "                tre+=1\n",
    "                \n",
    "\n",
    "    return np.array([zer, one, two, tre], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ca1a048-24c4-45e4-9918-1fd6008cdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1036    0    0    0]\n",
      " [   0  764    0    0]\n",
      " [   0    0  903    0]\n",
      " [   0    0    0 1077]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating stuff\n",
    "asd = np.concatenate([get_matrix(inx) for inx in range(4)])\n",
    "asd = asd.reshape(4,4)\n",
    "print(asd)\n",
    "asd = np.float32(asd)\n",
    "\n",
    "\n",
    "for i in range(len(asd)):\n",
    "    asd[i] = asd[i]/np.sum(asd[i])\n",
    "    \n",
    "mat = np.round(asd, 5)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f607d1-eef5-4edb-8dad-c3f6fe72a556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.heatmap(mat, annot=True)\n",
    "ax.set(xlabel=\"predictions\", ylabel=\"trues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406e4ab-50cb-4b6b-ad8c-8f5d5dbcf1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3adeb-78a3-46c6-99b5-cbd8c9e8dd55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
