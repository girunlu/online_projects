{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b733f5a-6e19-48d6-87a8-2e03c82d22c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check if CUDA is available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d44e51a4-133e-4c31-8bac-ca913948ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating the multiple tif image into single images  \n",
    "def separate(path, save_path):\n",
    "    # Open the TIFF file\n",
    "    im = Image.open(path)\n",
    "\n",
    "    # Iterate over the images in the TIFF file and save each image as a separate file\n",
    "    i = 0\n",
    "    try:\n",
    "        while True:\n",
    "            im.seek(i)\n",
    "            im.save(f'{save_path}image_{i}.tif')\n",
    "            i += 1\n",
    "    except EOFError:\n",
    "        pass\n",
    "\n",
    "# Specify the path where the TIFF files are located\n",
    "path = \"./DATA/\"\n",
    "\n",
    "# Iterate over each subdirectory in the specified path\n",
    "for i in os.listdir(path):\n",
    "    # Call the separate function for each TIFF file in the subdirectory\n",
    "    separate(path+i+\"/\"+os.listdir(path+i)[0], path+i+\"/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51289ece-2f14-4a34-9891-2e230d002495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET_down(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET_down, self).__init__()\n",
    "        \n",
    "        init_dim = 32\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, init_dim, 3, padding=1)\n",
    "        self.conv1_ = nn.Conv2d(init_dim, init_dim, 3, padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(init_dim, init_dim*2, 3, padding=1)\n",
    "        self.conv2_ = nn.Conv2d(init_dim*2, init_dim*2, 3, padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(init_dim*2, init_dim*4, 3, padding=1)\n",
    "        self.conv3_ = nn.Conv2d(init_dim*4, init_dim*4, 3, padding=1)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(init_dim*4, init_dim*8, 3, padding=1)\n",
    "        self.conv4_ = nn.Conv2d(init_dim*8, init_dim*8, 3, padding=1)\n",
    "        \n",
    "        self.BN1 = nn.BatchNorm2d(init_dim)\n",
    "        self.BN2 = nn.BatchNorm2d(init_dim*2)\n",
    "        self.BN3 = nn.BatchNorm2d(init_dim*4)\n",
    "        self.BN4 = nn.BatchNorm2d(init_dim*8)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #building unet parts (3 operations for each step)\n",
    "        x1 = self.conv1(x)\n",
    "        x1 = self.BN1(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        \n",
    "        x1 = self.conv1_(x1)\n",
    "        x1 = self.BN1(x1)\n",
    "        x1 = self.relu(x1) #256x256x64\n",
    "        x2 = self.maxpool(x1) #128x128x64\n",
    "        \n",
    "        x2 = self.conv2(x2)\n",
    "        x2 = self.BN2(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        \n",
    "        x2 = self.conv2_(x2)\n",
    "        x2 = self.BN2(x2)\n",
    "        x2 = self.relu(x2) #128x128x128\n",
    "        x3 = self.maxpool(x2) #64x64x128\n",
    "        \n",
    "        x3 = self.conv3(x3)\n",
    "        x3 = self.BN3(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        \n",
    "        x3 = self.conv3_(x3)\n",
    "        x3 = self.BN3(x3)\n",
    "        x3 = self.relu(x3) #64x64x256\n",
    "        x4 = self.maxpool(x3) #32x32x256\n",
    "        \n",
    "        x4 = self.conv4(x4)\n",
    "        x4 = self.BN4(x4)\n",
    "        x4 = self.relu(x4)\n",
    "        \n",
    "        x4 = self.conv4_(x4)\n",
    "        x4 = self.BN4(x4)\n",
    "        x4 = self.relu(x4) #32x32x512\n",
    "        x5 = self.maxpool(x4) #16x16x512\n",
    "        \n",
    "        x5 = self.conv4_(x5)\n",
    "        x5 = self.BN4(x5)\n",
    "        x5 = self.relu(x5)\n",
    "        \n",
    "        x5 = self.conv4_(x5)\n",
    "        x5 = self.BN4(x5)\n",
    "        x5 = self.relu(x5) #16x16x512\n",
    "        \n",
    "        return x1, x2, x3, x4, x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633ed796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNET_up(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET_up, self).__init__()\n",
    "        \n",
    "        init_dim = 512\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True) # upsampling\n",
    "        self.conv5 = nn.Conv2d(init_dim, init_dim//2, 3, padding=1)\n",
    "        self.conv5_ = nn.Conv2d(init_dim//2, init_dim//4, 3, padding=1)\n",
    "\n",
    "        self.BN5 = nn.BatchNorm2d(init_dim//2)\n",
    "        self.BN5_ = nn.BatchNorm2d(init_dim//4)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(init_dim//2, init_dim//4, 3, padding=1)\n",
    "        self.conv4_ = nn.Conv2d(init_dim//4, init_dim//8, 3, padding=1)\n",
    "\n",
    "        self.BN4 = nn.BatchNorm2d(init_dim//4)\n",
    "        self.BN4_ = nn.BatchNorm2d(init_dim//8)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(init_dim//4, init_dim//8, 3, padding=1)\n",
    "        self.conv3_ = nn.Conv2d(init_dim//8, init_dim//16, 3, padding=1)\n",
    "\n",
    "        self.BN3 = nn.BatchNorm2d(init_dim//8)\n",
    "        self.BN3_ = nn.BatchNorm2d(init_dim//16)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(init_dim//8, init_dim//16, 3, padding=1)\n",
    "        self.conv2_ = nn.Conv2d(init_dim//16, init_dim//16, 3, padding=1)\n",
    "\n",
    "        self.BN2 = nn.BatchNorm2d(init_dim//16)\n",
    "        self.BN2_ = nn.BatchNorm2d(init_dim//16)\n",
    "\n",
    "        self.convf = nn.Conv2d(init_dim//16,1,1,padding=0)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2, x3, x4, x5):\n",
    "        x5 = self.up(x5)\n",
    "        x = torch.cat([x4, x5], dim=1)\n",
    "\n",
    "        x = self.conv5(x)\n",
    "        x = self.BN5(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv5_(x)\n",
    "        x = self.BN5_(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x3, x], dim=1)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.BN4(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4_(x)\n",
    "        x = self.BN4_(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x2, x], dim=1)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.BN3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3_(x)\n",
    "        x = self.BN3_(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.up(x)\n",
    "        x = torch.cat([x1, x], dim=1)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.BN2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2_(x)\n",
    "        x = self.BN2_(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.convf(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadb4a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNET(\n",
       "  (convdown): UNET_down(\n",
       "    (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv1_): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (convup): UNET_up(\n",
       "    (relu): ReLU()\n",
       "    (up5): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv5): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv5_): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN5_): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv4_): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN4_): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv3_): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN3_): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (conv2_): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (BN2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (BN2_): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (convf): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class UNET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNET, self).__init__()\n",
    "\n",
    "        # Initialize the UNET_down and UNET_up components\n",
    "        self.convdown = UNET_down()\n",
    "        self.convup = UNET_up()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass of the UNet model\n",
    "        x1, x2, x3, x4, x5 = self.convdown(x)\n",
    "        x = self.convup(x1, x2, x3, x4, x5)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the UNET model\n",
    "model = UNET()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbd8cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class datagen(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        # Initialize the required parameters\n",
    "        self.img_dir = img_dir  # Directory containing the input images\n",
    "        self.mask_dir = mask_dir  # Directory containing the corresponding masks\n",
    "        self.transform = transform  # Transformation to be applied to the images and masks\n",
    "        self.img_filenames = os.listdir(self.img_dir)  # List of image filenames in the directory\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the dataset (number of images)\n",
    "        return len(self.img_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Accessing the data at the given index\n",
    "\n",
    "        # Get the paths of the image and mask for the current index\n",
    "        img_path = os.path.join(self.img_dir, self.img_filenames[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.img_filenames[idx])\n",
    "\n",
    "        # Read the image and mask using PIL.Image and convert them to grayscale\n",
    "        image = Image.open(img_path).convert(\"L\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        # Apply the specified transformation to the image and mask\n",
    "        image, mask = self.transform(image), self.transform(mask)\n",
    "\n",
    "        # Return the transformed image and mask as the dataset sample\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f94c5906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation pipeline for the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the image and mask to a fixed size of 256x256\n",
    "    transforms.ToTensor(),  # Convert the image and mask to tensors\n",
    "])\n",
    "\n",
    "# Specify the path to the data directory\n",
    "path = \"./DATA\"\n",
    "\n",
    "# Get the subdirectories in the data directory\n",
    "dirs = [os.path.join(path, i) for i in os.listdir(\"./DATA\")]\n",
    "\n",
    "# Assign the subdirectories to corresponding variables\n",
    "trainx_dir, testx_dir, testy_dir, trainy_dir = dirs\n",
    "\n",
    "# Create the training and testing dataset\n",
    "train_dataset = datagen(trainx_dir, trainy_dir, transform)\n",
    "test_dataset = datagen(testx_dir, testy_dir, transform)\n",
    "\n",
    "# Create the training and testing data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=15, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=15, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fbc11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # output and target are assumed to be (N, C, H, W), where N is batch size, C is num of classes\n",
    "        # convert to (N, H, W, C)\n",
    "        output = output.permute(0, 2, 3, 1)\n",
    "        target = target.permute(0, 2, 3, 1)\n",
    "\n",
    "        # Flatten the tensor\n",
    "        output = output.contiguous().view(-1)\n",
    "        target = target.contiguous().view(-1)\n",
    "\n",
    "        intersection = (output * target).sum()  # Compute the intersection between output and target\n",
    "        dice_coef = (2. * intersection + self.eps) / (output.sum() + target.sum() + self.eps)\n",
    "\n",
    "        return 1. - dice_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06204467-ac64-483e-b7d4-6fe36e544693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 0.81130\n",
      "epoch: 2, loss: 0.77492\n",
      "epoch: 3, loss: 0.67392\n",
      "epoch: 4, loss: 0.55636\n",
      "epoch: 5, loss: 0.43544\n",
      "epoch: 6, loss: 0.24960\n",
      "epoch: 7, loss: 0.15935\n",
      "epoch: 8, loss: 0.11874\n",
      "epoch: 9, loss: 0.10617\n",
      "lr was 0.005000, will be 0.002500\n",
      "epoch: 10, loss: 0.08393\n",
      "epoch: 11, loss: 0.07896\n",
      "epoch: 12, loss: 0.07699\n",
      "epoch: 13, loss: 0.07150\n",
      "epoch: 14, loss: 0.07358\n",
      "epoch: 15, loss: 0.07847\n",
      "epoch: 16, loss: 0.06059\n",
      "epoch: 17, loss: 0.05785\n",
      "epoch: 18, loss: 0.06375\n",
      "epoch: 19, loss: 0.06632\n",
      "lr was 0.002500, will be 0.000625\n",
      "epoch: 20, loss: 0.05902\n",
      "epoch: 21, loss: 0.05414\n",
      "epoch: 22, loss: 0.05290\n",
      "epoch: 23, loss: 0.05739\n",
      "epoch: 24, loss: 0.05298\n",
      "epoch: 25, loss: 0.06132\n",
      "epoch: 26, loss: 0.05751\n",
      "epoch: 27, loss: 0.05386\n",
      "epoch: 28, loss: 0.05257\n",
      "epoch: 29, loss: 0.05588\n",
      "lr was 0.000625, will be 0.000104\n",
      "epoch: 30, loss: 0.05347\n"
     ]
    }
   ],
   "source": [
    "#training loop\n",
    "num_epochs = 30\n",
    "total_step = len(train_loader)\n",
    "lr = 5e-3\n",
    "\n",
    "loss_fn = DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move inputs and targets to the specified device (CPU or CUDA)\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(inputs)\n",
    "        loss = loss_fn(preds, targets.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Clear GPU memory cache\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # Adjust learning rate every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"lr was {lr:.6f}, will be {lr / (2 * (epoch // 10)):.6f}\")\n",
    "        lr /= (2 * (epoch // 10))\n",
    "\n",
    "    # Print epoch number and current loss\n",
    "    print(f\"epoch: {epoch}, loss: {loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d9b91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d8993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
